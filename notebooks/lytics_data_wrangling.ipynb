{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Lytics Profile Data - Tools and Techniques\n",
    "\n",
    "The goal of this notebook is to present some tools and techniques that can be used to wrangle Industry Dive data. \n",
    "\n",
    "## What is Data Wrangling again?\n",
    ">Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.  Some transformation techniques include: parsing, joining, standardizing, augmenting, cleansing, and consolidating. \n",
    "\n",
    "[per wikipedia](https://en.wikipedia.org/wiki/Data_wrangling)\n",
    "\n",
    "## Bad Data in, Bad Data out\n",
    "\n",
    "![bad data in bad data out](https://cdn-images-1.medium.com/max/1200/0*YCghEemt6BtW9OZV.png \"Bad Data in Bad Data out\")\n",
    "\n",
    "Many websites contain forms in order to collect information from users for various reasons.  In our case, we have signup forms for dives that asks for information about our users like so:\n",
    "\n",
    "![signup form](../data/img/signup_form.png \"signup form\")\n",
    "\n",
    "As you can see, there are fields that are restricted to pre-defined values (e.g., Job Function), and free-form fields (e.g., Company Name) where a user can type most anything they like.  Whenever users are exposed to free-form fields, there is a possibility of bad/messy/non-standardized data making into your system.\n",
    "\n",
    "For example, here are some variants of \"IKEA\" that are present for user profiles that we have:\n",
    "\n",
    "* IKEA\n",
    "* IKEA AG\n",
    "* IKEA Belgium\n",
    "* IKEA Canada\n",
    "* IKEA Danville\n",
    "* IKEA Food\n",
    "* IKEA Home Furnishings\n",
    "* IKEA Portugal\n",
    "* IKEA USA\n",
    "* IKEA US EAST, LLC 215\n",
    "* IKEA US\n",
    "\n",
    "Without some wrangling, you would not be able to aggregate these folks properly into a single group based on company.\n",
    "\n",
    "## Lytics Profile Data\n",
    "Now, let's take a look at some Lytics profile data, which consists of all information we have about users who interact with our content.  Within this data, there are key demographic fields that can help us understand who our users are, such as:\n",
    "* first and last name\n",
    "* job title\n",
    "* email domain\n",
    "* company name\n",
    "* address\n",
    "\n",
    "The data file we are going to look at is an export of the \"All\" audience segment in Lytics.\n",
    "https://activate.getlytics.com/audiences/4cc5d612f46fb86e5cfd0c995250e60c/summary?aid=2751\n",
    "\n",
    "![All Audience segment in Lytics](../data/img/lytics_all_audience_segment.png \"All Audience segment in Lytics\")\n",
    "\n",
    "Let's start looking at this data to see how we can clean it up in order to help us create more accurate statistics about our users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'company_name', 'domain', 'emaildomain', 'emaildomains', 'st_profile_id', 'user_id', 'lytics_segment']\n",
      "# of rows left: 782425\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/files/lytics_profile_data_export.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "\n",
    "# list columns in dataset\n",
    "print(list(df))\n",
    "\n",
    "# number of rows\n",
    "print('# of rows left: %s' % df.shape[0])\n",
    "# print(df[df['st_profile_id'].str.contains(\"5a2ba1f6ff530ac11a8b4868\", na=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple fields in the data we can choose to cleanup, but first let's look at the \"company_name\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows left: 458289\n"
     ]
    }
   ],
   "source": [
    "# remove null company name values\n",
    "df = df.dropna(subset=['company_name'])\n",
    "\n",
    "# number of rows\n",
    "print('# of rows left: %s' % df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..' '.' '...' '*' '********' '......' ',' '.....' '***' '????????' '?'\n",
      " '**' '.......' ',,' '@@']\n",
      "# of special character value rows: 103\n",
      "# of rows left: 458186\n"
     ]
    }
   ],
   "source": [
    "# find values that are any combination of special characters\n",
    "special_char_values = df['company_name'].str.contains(\"^[!@#$%^&*(),.?]*$\", na=False)\n",
    "print(df[special_char_values].company_name.unique())\n",
    "\n",
    "# number of rows\n",
    "print('# of special character value rows: %s' % df[special_char_values].shape[0])\n",
    "df = df[~special_char_values]\n",
    "\n",
    "print('# of rows left: %s' % df.shape[0])\n",
    "# print(df[df['st_profile_id'].str.contains(\"5a2ba1f6ff530ac11a8b4868\", na=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1948' '1989' '1954' '451' '1957' '1979' '252' '1953' '1967' '8020'\n",
      " '1960' '5' '104' '1999' '123' '1974' '1988' '1977' '1000' '900' '1956'\n",
      " '605' '8760' '1984' '1959' '1998' '1972' '1992' '1997' '1991' '111'\n",
      " '1990' '1987' '1970' '1969' '1965' '1968' '1995' '1993' '1975' '1963'\n",
      " '231112027' '53' '1976' '1985' '1949' '149' '0' '1971' '1986' '346'\n",
      " '47723' '1947' '94122202312' '1' '1958' '1973' '43' '1935' '1961' '1994'\n",
      " '1946' '325024080134' '1996' '1982' '15' '34' '1952' '271' '1980' '1966'\n",
      " '1936' '47' '1978' '1964' '1928' '50' '2714' '1955' '1690' '1942' '13'\n",
      " '05358359981' '9172077326' '12' '151' '1951' '2000' '400000000000' '2'\n",
      " '1905' '2020' '1940' '1983' '2008' '198' '2013' '1962' '411' '2015' '295'\n",
      " '1950' '940005848995' '11455' '83255804' '2166833' '1001' '6' '91957'\n",
      " '14' '887000000000' '666' '59' '963' '32000' '555' '404' '0789243438'\n",
      " '438' '68' '1945' '525' '825' '2009' '1981' '8001504151' '136' '359'\n",
      " '365' '308' '940003979987' '6164381822' '1107' '0673282495' '2040' '745'\n",
      " '3211' '1871' '40041466109' '10' '1776' '1931' '2005' '8121066529'\n",
      " '42149777' '173' '130' '3' '3300909815' '458' '2019' '352158191' '347'\n",
      " '777' '701010' '002435500285' '983' '256' '940004104374' '918015150236'\n",
      " '28' '929' '591' '19' '2012' '719' '7' '465' '42' '207' '360' '2016' '54'\n",
      " '6489' '58']\n",
      "# of number value rows: 721\n",
      "# of rows left: 457465\n"
     ]
    }
   ],
   "source": [
    "# find values that are only numbers\n",
    "number_values = df['company_name'].str.contains(\"^[0-9]*$\", na=False)\n",
    "print(df[number_values].company_name.unique())\n",
    "\n",
    "# number of rows\n",
    "print('# of number value rows: %s' % df[number_values].shape[0])\n",
    "df = df[~number_values]\n",
    "\n",
    "print('# of rows left: %s' % df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows left: 457462\n"
     ]
    }
   ],
   "source": [
    "# random additional values that I found when I was looking at the data in Excel\n",
    "weird_vals = ['#NAME?', '{Re}', '< self >']\n",
    "weird_values = df['company_name'].isin(weird_vals)\n",
    "df = df[~weird_values]\n",
    "\n",
    "# left over rows in dataframe\n",
    "print('# of rows left: %s' % df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned all the bad company name values from our dataset, let's work on standardizing the names to help with comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values to all lower case\n",
    "df['stndrdzed_company_name'] = df['company_name'].str.lower()\n",
    "# remove all punctuation\n",
    "df[\"stndrdzed_company_name\"] = df['stndrdzed_company_name'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# remove rows with \"none\" as value\n",
    "none_rows = df['stndrdzed_company_name'].str.contains('none', na=False)\n",
    "df = df[~none_rows]\n",
    "\n",
    "# remove rows with \"\" as value\n",
    "empty_string_rows = df['stndrdzed_company_name'].values == ''\n",
    "df = df[~empty_string_rows]\n",
    "\n",
    "# df.sort_values(by=['stndrdzed_company_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our dataset to see what we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stndrdzed_company_name</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>20160506deleteme</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214673</th>\n",
       "      <td>self</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115522</th>\n",
       "      <td>ibm</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263824</th>\n",
       "      <td>walmart</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>accenture</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147255</th>\n",
       "      <td>macys</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230752</th>\n",
       "      <td>student</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72555</th>\n",
       "      <td>duke energy</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163621</th>\n",
       "      <td>mr</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214692</th>\n",
       "      <td>self employed</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235724</th>\n",
       "      <td>target</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173896</th>\n",
       "      <td>novartis</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203159</th>\n",
       "      <td>retired</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264512</th>\n",
       "      <td>waste management</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196171</th>\n",
       "      <td>pwc</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186641</th>\n",
       "      <td>pfizer</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65683</th>\n",
       "      <td>deloitte</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100383</th>\n",
       "      <td>google</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56303</th>\n",
       "      <td>consultant</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>amazon</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271713</th>\n",
       "      <td>xcel energy</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202363</th>\n",
       "      <td>republic services</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224607</th>\n",
       "      <td>southern california edison</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13549</th>\n",
       "      <td>amgen</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166903</th>\n",
       "      <td>national grid</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179351</th>\n",
       "      <td>oracle</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210887</th>\n",
       "      <td>sanofi</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>american electric power</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185693</th>\n",
       "      <td>pepsico</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84585</th>\n",
       "      <td>ey</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99852</th>\n",
       "      <td>golden rays of hope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99851</th>\n",
       "      <td>golden pony casino</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99836</th>\n",
       "      <td>golden nugget lake charles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99821</th>\n",
       "      <td>golden homes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99822</th>\n",
       "      <td>golden hour farm llc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99823</th>\n",
       "      <td>golden isles medical billing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99824</th>\n",
       "      <td>golden krust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99825</th>\n",
       "      <td>golden krust bakery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99826</th>\n",
       "      <td>golden krust caribbean bakery inc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99829</th>\n",
       "      <td>golden living village gardens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99830</th>\n",
       "      <td>golden media service provider</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99832</th>\n",
       "      <td>golden nugget atlantic city</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99833</th>\n",
       "      <td>golden nugget biloxi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99834</th>\n",
       "      <td>golden nugget casino hotel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99835</th>\n",
       "      <td>golden nugget flea market</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99837</th>\n",
       "      <td>golden nugget online</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99850</th>\n",
       "      <td>golden polytech pvt ltd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99838</th>\n",
       "      <td>golden olives academy abuja</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99839</th>\n",
       "      <td>golden one credit union</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99840</th>\n",
       "      <td>golden opportunities</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99841</th>\n",
       "      <td>golden pack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99842</th>\n",
       "      <td>golden palace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99843</th>\n",
       "      <td>golden palm advisors</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99844</th>\n",
       "      <td>golden pass lng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99845</th>\n",
       "      <td>golden pasta flour mills of nigeria plc nigeria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99846</th>\n",
       "      <td>golden peacock consulting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99847</th>\n",
       "      <td>golden peanut  tree nuts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99848</th>\n",
       "      <td>golden peanut and tree nuts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99849</th>\n",
       "      <td>golden platter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275265</th>\n",
       "      <td>현대엔지니어링</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 stndrdzed_company_name  counts\n",
       "449                                    20160506deleteme    1364\n",
       "214673                                             self     692\n",
       "115522                                              ibm     545\n",
       "263824                                          walmart     523\n",
       "3715                                          accenture     512\n",
       "147255                                            macys     444\n",
       "230752                                          student     414\n",
       "72555                                       duke energy     412\n",
       "163621                                               mr     384\n",
       "214692                                    self employed     379\n",
       "235724                                           target     378\n",
       "173896                                         novartis     350\n",
       "203159                                          retired     338\n",
       "264512                                 waste management     335\n",
       "196171                                              pwc     325\n",
       "186641                                           pfizer     324\n",
       "65683                                          deloitte     317\n",
       "100383                                           google     317\n",
       "56303                                        consultant     316\n",
       "12326                                            amazon     313\n",
       "271713                                      xcel energy     304\n",
       "202363                                republic services     303\n",
       "224607                       southern california edison     292\n",
       "13549                                             amgen     290\n",
       "166903                                    national grid     288\n",
       "179351                                           oracle     287\n",
       "210887                                           sanofi     285\n",
       "12831                           american electric power     285\n",
       "185693                                          pepsico     276\n",
       "84585                                                ey     275\n",
       "...                                                 ...     ...\n",
       "99852                               golden rays of hope       1\n",
       "99851                                golden pony casino       1\n",
       "99836                        golden nugget lake charles       1\n",
       "99821                                      golden homes       1\n",
       "99822                              golden hour farm llc       1\n",
       "99823                      golden isles medical billing       1\n",
       "99824                                      golden krust       1\n",
       "99825                               golden krust bakery       1\n",
       "99826                 golden krust caribbean bakery inc       1\n",
       "99829                     golden living village gardens       1\n",
       "99830                     golden media service provider       1\n",
       "99832                       golden nugget atlantic city       1\n",
       "99833                              golden nugget biloxi       1\n",
       "99834                        golden nugget casino hotel       1\n",
       "99835                         golden nugget flea market       1\n",
       "99837                              golden nugget online       1\n",
       "99850                           golden polytech pvt ltd       1\n",
       "99838                       golden olives academy abuja       1\n",
       "99839                           golden one credit union       1\n",
       "99840                              golden opportunities       1\n",
       "99841                                       golden pack       1\n",
       "99842                                     golden palace       1\n",
       "99843                              golden palm advisors       1\n",
       "99844                                   golden pass lng       1\n",
       "99845   golden pasta flour mills of nigeria plc nigeria       1\n",
       "99846                         golden peacock consulting       1\n",
       "99847                          golden peanut  tree nuts       1\n",
       "99848                       golden peanut and tree nuts       1\n",
       "99849                                    golden platter       1\n",
       "275265                                          현대엔지니어링       1\n",
       "\n",
       "[275266 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('stndrdzed_company_name')\n",
    "\n",
    "grouped = grouped.size().reset_index(name='counts')\n",
    "grouped.sort_values(by=['counts'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note from looking at this is that there are company names that contain values other than English.  For instance, \"현대엔지니어링\" is Korean.  This is one thing you could work on eliminating as well if you wanted to focus on English values.  I tried to use a library called \"langdetect\" for this, but it did not do a good job of picking up the obvious cases.\n",
    "\n",
    "Once we have wrangled the data bit, we can now try to enhance our dataset with an external dataset.  One of the datasets we bought rights to recently, DiscoverOrg, has different information about companies that could be usefull for analysis.  The common field these two datasets have is the company name.  So we can try to load this dataset and match the two up based on company name in order to enhance our existing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/files/DiscoverOrg_Company_223030_20180731141156.csv', encoding='latin-1', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "\n",
    "# change the values to all lower case\n",
    "df2['stndrdzed_company_name'] = df2['Company Name'].astype(str).str.lower()\n",
    "# remove all punctuation\n",
    "df2[\"stndrdzed_company_name\"] = df2['stndrdzed_company_name'].str.replace('[^\\w\\s]','')\n",
    "df2.columns = ['company_id', 'company_name', 'domain','company_primary_industry','hq_country']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases\n",
    "\n",
    "### Company Name\n",
    "First, we will look at some techniques to apply to our dataset based on a recent request from Audience Dev.  They would like to create aggregate statistics about our users based on company name, so this will be the basis upon which we will transform our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with discovery org data in order to find matches\n",
    "merge = pd.merge(df, df2, how='inner', on=['stndrdzed_company_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18927"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = merge.groupby('stndrdzed_company_name')\n",
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
