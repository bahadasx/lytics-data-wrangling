{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Lytics Profile Data - Tools and Techniques\n",
    "\n",
    "The goal of this notebook is to present some tools and techniques that can be used to wrangle Industry Dive data. \n",
    "\n",
    "## What is Data Wrangling again?\n",
    ">Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \"raw\" >data form into another format with the intent of making it more appropriate and valuable for a variety of downstream >purposes such as analytics.  Some transformation techniques include: parsing, joining, standardizing, augmenting, >cleansing, and consolidating. \n",
    "\n",
    "[per wikipedia](https://en.wikipedia.org/wiki/Data_wrangling)\n",
    "\n",
    "## Bad Data in, Bad Data out\n",
    "\n",
    "![bad data in bad data out](https://cdn-images-1.medium.com/max/1200/0*YCghEemt6BtW9OZV.png \"Bad Data in Bad Data out\")\n",
    "\n",
    "Many websites contain forms in order to collect information from users for various reasons.  In our case, we have signup forms for dives that asks for information about our users like so:\n",
    "\n",
    "![signup form](../data/img/signup_form.png \"signup form\")\n",
    "\n",
    "As you can see, there are fields that are restricted to pre-defined values (e.g., Job Function), and free-form fields (e.g., Company Name) where a user can type most anything they like.  Whenever users are exposed to free-form fields, there is a possibility of bad/messy/non-standardized data making into your system.\n",
    "\n",
    "For example, here are some variants of \"IKEA\" that are present for user profiles that we have:\n",
    "\n",
    "* IKEA\n",
    "* IKEA AG\n",
    "* IKEA Belgium\n",
    "* IKEA Canada\n",
    "* IKEA Danville\n",
    "* IKEA Food\n",
    "* IKEA Home Furnishings\n",
    "* IKEA Portugal\n",
    "* IKEA USA\n",
    "* IKEA US EAST, LLC 215\n",
    "* IKEA US\n",
    "\n",
    "Without some wrangling, you would not be able to aggregate these folks properly into a single group based on company.\n",
    "\n",
    "## Lytics Profile Data\n",
    "We now use Lytics in order to house all data we know about users who interact with our content.  This data comes from many systems, but regardless of source, there are certain demographic fields in this dataset that can help us understand who our users are, such as:\n",
    "* first and last name\n",
    "* job title\n",
    "* email domain\n",
    "* company name\n",
    "* address\n",
    "\n",
    "The data file being used for this notebook is an export of the \"All\" audience segment in Lytics.\n",
    "https://activate.getlytics.com/audiences/4cc5d612f46fb86e5cfd0c995250e60c/summary?aid=2751\n",
    "\n",
    "![All Audience segment in Lytics](../data/img/lytics_all_audience_segment.png \"All Audience segment in Lytics\")\n",
    "\n",
    "First, we will load our data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company',\n",
       " 'company_name',\n",
       " 'domain',\n",
       " 'emaildomain',\n",
       " 'emaildomains',\n",
       " 'st_profile_id',\n",
       " 'user_id',\n",
       " 'lytics_segment']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/files/lytics_profile_data_export.csv', encoding='latin-1')\n",
    "# list columns in dataset\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple fields in the data we can choose to cleanup, but first let's look at the \"company_name\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..',\n",
       " '.',\n",
       " '...',\n",
       " '*',\n",
       " '********',\n",
       " '......',\n",
       " ',',\n",
       " '.....',\n",
       " '***',\n",
       " '????????',\n",
       " '?',\n",
       " '**',\n",
       " '.......',\n",
       " ',,',\n",
       " '@@']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove null company name values\n",
    "company_names = df.dropna(subset=['company_name'])\n",
    "# filter to only unique values\n",
    "unique_company_names = list(company_names.company_name.unique())\n",
    "# find values that are any combination of special characters\n",
    "import re\n",
    "r = re.compile(\"^[!@#$%^&*(),.?]*$\")\n",
    "special_chars_values = list(filter(r.match, unique_company_names))\n",
    "special_chars_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1948',\n",
       " '1989',\n",
       " '1954',\n",
       " '451',\n",
       " '1957',\n",
       " '1979',\n",
       " '252',\n",
       " '1953',\n",
       " '1967',\n",
       " '8020',\n",
       " '1960',\n",
       " '5',\n",
       " '104',\n",
       " '1999',\n",
       " '123',\n",
       " '1974',\n",
       " '1988',\n",
       " '1977',\n",
       " '1000',\n",
       " '900',\n",
       " '1956',\n",
       " '605',\n",
       " '8760',\n",
       " '1984',\n",
       " '1959',\n",
       " '1998',\n",
       " '1972',\n",
       " '1992',\n",
       " '1997',\n",
       " '1991',\n",
       " '111',\n",
       " '1990',\n",
       " '1987',\n",
       " '1970',\n",
       " '1969',\n",
       " '1965',\n",
       " '1968',\n",
       " '1995',\n",
       " '1993',\n",
       " '1975',\n",
       " '1963',\n",
       " '231112027',\n",
       " '53',\n",
       " '1976',\n",
       " '1985',\n",
       " '1949',\n",
       " '149',\n",
       " '0',\n",
       " '1971',\n",
       " '1986',\n",
       " '346',\n",
       " '47723',\n",
       " '1947',\n",
       " '94122202312',\n",
       " '1',\n",
       " '1958',\n",
       " '1973',\n",
       " '43',\n",
       " '1935',\n",
       " '1961',\n",
       " '1994',\n",
       " '1946',\n",
       " '325024080134',\n",
       " '1996',\n",
       " '1982',\n",
       " '15',\n",
       " '34',\n",
       " '1952',\n",
       " '271',\n",
       " '1980',\n",
       " '1966',\n",
       " '1936',\n",
       " '47',\n",
       " '1978',\n",
       " '1964',\n",
       " '1928',\n",
       " '50',\n",
       " '2714',\n",
       " '1955',\n",
       " '1690',\n",
       " '1942',\n",
       " '13',\n",
       " '05358359981',\n",
       " '9172077326',\n",
       " '12',\n",
       " '151',\n",
       " '1951',\n",
       " '2000',\n",
       " '400000000000',\n",
       " '2',\n",
       " '1905',\n",
       " '2020',\n",
       " '1940',\n",
       " '1983',\n",
       " '2008',\n",
       " '198',\n",
       " '2013',\n",
       " '1962',\n",
       " '411',\n",
       " '2015',\n",
       " '295',\n",
       " '1950',\n",
       " '940005848995',\n",
       " '11455',\n",
       " '83255804',\n",
       " '2166833',\n",
       " '1001',\n",
       " '6',\n",
       " '91957',\n",
       " '14',\n",
       " '887000000000',\n",
       " '666',\n",
       " '59',\n",
       " '963',\n",
       " '32000',\n",
       " '555',\n",
       " '404',\n",
       " '0789243438',\n",
       " '438',\n",
       " '68',\n",
       " '1945',\n",
       " '525',\n",
       " '825',\n",
       " '2009',\n",
       " '1981',\n",
       " '8001504151',\n",
       " '136',\n",
       " '359',\n",
       " '365',\n",
       " '308',\n",
       " '940003979987',\n",
       " '6164381822',\n",
       " '1107',\n",
       " '0673282495',\n",
       " '2040',\n",
       " '745',\n",
       " '3211',\n",
       " '1871',\n",
       " '40041466109',\n",
       " '10',\n",
       " '1776',\n",
       " '1931',\n",
       " '2005',\n",
       " '8121066529',\n",
       " '42149777',\n",
       " '173',\n",
       " '130',\n",
       " '3',\n",
       " '3300909815',\n",
       " '458',\n",
       " '2019',\n",
       " '352158191',\n",
       " '347',\n",
       " '777',\n",
       " '701010',\n",
       " '002435500285',\n",
       " '983',\n",
       " '256',\n",
       " '940004104374',\n",
       " '918015150236',\n",
       " '28',\n",
       " '929',\n",
       " '591',\n",
       " '19',\n",
       " '2012',\n",
       " '719',\n",
       " '7',\n",
       " '465',\n",
       " '42',\n",
       " '207',\n",
       " '360',\n",
       " '2016',\n",
       " '54',\n",
       " '6489',\n",
       " '58']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find values that are only numbers\n",
    "r = re.compile(\"^[0-9]*$\")\n",
    "number_values = list(filter(r.match, unique_company_names))\n",
    "number_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'company_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-4ba70e920053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompany_names_to_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial_chars_values\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumber_values\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweird_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df = df[df.company_name not in values_to_remove]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_names_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'company_name'"
     ]
    }
   ],
   "source": [
    "weird_vals = ['#NAME?']\n",
    "\n",
    "# remove all the rows with bad company name values\n",
    "company_names_to_remove = special_chars_values + number_values + weird_vals\n",
    "#df = df[df.company_name not in values_to_remove]\n",
    "df[~df.company_name.isin(company_names_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Cases\n",
    "\n",
    "### Company Name\n",
    "First, we will look at some techniques to apply to our dataset based on a recent request from Audience Dev.  They would like to create aggregate statistics about our users based on company name, so this will be the basis upon which we will transform our data.\n",
    "\n",
    "That lytics export file (782,426 rows/50.7 MB) made my RAM unhappy, so I decided to cut the file down based on the above-stated use case.  \n",
    "\n",
    "\n",
    "First, I removed all rows from the file which had a blank Company Name.  Next, I removed some obvious bad data (e.g., \"*\", \"11\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lytics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_org = pd.read_csv('DiscoverOrg_Company_223030_20180731141156.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lytics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_org.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_org.columns = ['company_id', 'company_name', 'domain','company_primary_industry','hq_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_disc_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(df_lytics, df_disc_org, how='inner', on=['company_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
